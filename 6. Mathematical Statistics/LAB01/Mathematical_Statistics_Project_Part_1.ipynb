{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e164b769",
   "metadata": {},
   "source": [
    "# Mathematical Statistics Project - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa2adf",
   "metadata": {},
   "source": [
    "### Naive Bayes Algorithm: Spam/Ham Classification\n",
    "\n",
    "Naive Bayes is a simple yet powerful probabilistic classifier based on Bayes' Theorem, with the assumption that the features (words in our case) are independent. In the context of email classification, it is used to classify emails as either \"spam\" or \"ham\" (non-spam). Below is a step-by-step explanation of how Naive Bayes works for this task:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Understanding Bayes' Theorem**\n",
    "\n",
    "The algorithm uses **Bayes’ Theorem** to compute the probability of an email being spam given the words it contains. Bayes’ Theorem is expressed as:\n",
    "\n",
    "\n",
    "$$P(\\text{spam} | \\text{email}) = \\frac{P(\\text{email} | \\text{spam}) \\cdot P(\\text{spam})}{P(\\text{email})}$$\n",
    "\n",
    "\n",
    "Where:\n",
    "- $P(\\text{spam} | \\text{email})$ is the posterior probability of the email being spam, given that the words in the email are known.\n",
    "- $P(\\text{email} | \\text{spam})$ is the likelihood of seeing those words in a spam email.\n",
    "- $P(\\text{spam})$ is the prior probability of any random email being spam.\n",
    "- $P(\\text{email})$ is the probability of those words appearing in any email (this acts as a normalization factor).\n",
    "\n",
    "Since $P(\\text{email})$ is constant for both spam and ham classification, it can be ignored for comparison purposes.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Defining the Problem (Feature Set)**\n",
    "\n",
    "In this example, the features are the words in the email. For simplicity, let's assume we have a vocabulary with three words: `money`, `win`, and `lottery`.\n",
    "\n",
    "The email to classify is: **“win money lottery”**\n",
    "\n",
    "We want to calculate:\n",
    "\n",
    "$P(\\text{spam} | \\text{win money lottery}) \\quad \\text{vs} \\quad P(\\text{ham} | \\text{win money lottery})$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Collecting Probabilities from Training Data**\n",
    "\n",
    "We need the following probabilities from the training data:\n",
    "\n",
    "1. **Prior Probabilities**:\n",
    "   - $P(\\text{spam})$: Probability that any random email is spam.\n",
    "   - $P(\\text{ham})$: Probability that any random email is ham.\n",
    "\n",
    "2. **Likelihood Probabilities**:\n",
    "   - $P(\\text{win} | \\text{spam})$: Probability that \"win\" appears in a spam email.\n",
    "   - $P(\\text{money} | \\text{spam})$: Probability that \"money\" appears in a spam email.\n",
    "   - $P(\\text{lottery} | \\text{spam})$: Probability that \"lottery\" appears in a spam email.\n",
    "   - Similar probabilities for the words in ham emails.\n",
    "\n",
    "### Example:\n",
    "Suppose we have training data that results in the following counts:\n",
    "\n",
    "- Out of 1000 emails:\n",
    "  - 400 are spam emails, and 600 are ham emails.\n",
    "  \n",
    "  From spam emails:\n",
    "  - \"win\" appears in 300 out of 400 spam emails.\n",
    "  - \"money\" appears in 350 out of 400 spam emails.\n",
    "  - \"lottery\" appears in 200 out of 400 spam emails.\n",
    "\n",
    "  From ham emails:\n",
    "  - \"win\" appears in 100 out of 600 ham emails.\n",
    "  - \"money\" appears in 150 out of 600 ham emails.\n",
    "  - \"lottery\" appears in 50 out of 600 ham emails.\n",
    "\n",
    "#### **Calculating Prior Probabilities**:\n",
    "- $P(\\text{spam}) = \\frac{400}{1000} = 0.4$\n",
    "- $P(\\text{ham}) = \\frac{600}{1000} = 0.6$\n",
    "\n",
    "#### **Calculating Likelihood Probabilities**:\n",
    "For spam:\n",
    "- $P(\\text{win} | \\text{spam}) = \\frac{300}{400} = 0.75$\n",
    "- $P(\\text{money} | \\text{spam}) = \\frac{350}{400} = 0.875$\n",
    "- $P(\\text{lottery} | \\text{spam}) = \\frac{200}{400} = 0.5$\n",
    "\n",
    "For ham:\n",
    "- $P(\\text{win} | \\text{ham}) = \\frac{100}{600} = 0.167$\n",
    "- $P(\\text{money} | \\text{ham}) = \\frac{150}{600} = 0.25$\n",
    "- $P(\\text{lottery} | \\text{ham}) = \\frac{50}{600} = 0.083$\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Applying Naive Bayes Formula**\n",
    "\n",
    "We now calculate the **posterior probabilities** for both spam and ham:\n",
    "\n",
    "#### For Spam:\n",
    "\n",
    "$P(\\text{spam} | \\text{win money lottery}) \\propto P(\\text{spam}) \\cdot P(\\text{win} | \\text{spam}) \\cdot P(\\text{money} | \\text{spam}) \\cdot P(\\text{lottery} | \\text{spam})$\n",
    "Substitute the values:\n",
    "\n",
    "$P(\\text{spam} | \\text{win money lottery}) \\propto 0.4 \\cdot 0.75 \\cdot 0.875 \\cdot 0.5 = 0.13125$\n",
    "\n",
    "#### For Ham:\n",
    "\n",
    "$P(\\text{ham} | \\text{win money lottery}) \\propto P(\\text{ham}) \\cdot P(\\text{win} | \\text{ham}) \\cdot P(\\text{money} | \\text{ham}) \\cdot P(\\text{lottery} | \\text{ham})$\n",
    "Substitute the values:\n",
    "\n",
    "$P(\\text{ham} | \\text{win money lottery}) \\propto 0.6 \\cdot 0.167 \\cdot 0.25 \\cdot 0.083 = 0.00208$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Normalization & Decision**\n",
    "\n",
    "Although we can normalize the values to get actual probabilities, we can directly compare the two quantities:\n",
    "\n",
    "- $P(\\text{spam} | \\text{win money lottery}) = 0.13125$\n",
    "- $P(\\text{ham} | \\text{win money lottery}) = 0.00208$\n",
    "\n",
    "Since $P(\\text{spam} | \\text{win money lottery})$ is much larger than $P(\\text{ham} | \\text{win money lottery})$, we classify the email as **Spam**.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Handling Zero Probabilities (Smoothing)**\n",
    "\n",
    "In practice, some words may not appear in the training set for spam or ham, leading to zero probabilities (e.g., $P(\\text{win} | \\text{spam}) = 0$). To avoid this we assume that each word appeard at least in one Spam email and one ham email, i.e., we start counting each word from 1.\n",
    "\n",
    "---\n",
    "\n",
    "### **Tasks**\n",
    "\n",
    "The task is to implement the Naive Bayes algorithm from scratch. You will use the attached **emails.csv** file for this task.\n",
    "\n",
    "The first step is to preprocess the emails text and transform it into an easier format. An important step in preprocessing the text is to remove what is called **stopwords**. These are words that exist in the text but does not convey much information like prepositions and pronouns. The same holds for punctuations which needs to be removed as well. The second step is called **tokenization** where the email words are split and stored as an array of tokens (words).\n",
    "\n",
    "To help you through this part, the code snippet provided for you below provides useful instructions to load the data as a Pandas DataFrame and uses the **NLTK** library to remove stopwords. Use the **preprocessing** function provided to get a cleaned and tokenized version of the emails. The last code snippet provided for you is for splitting the data into training and testing sets.\n",
    "\n",
    "To implement the Naive Bayes algorithm you need to write functions to estimate the following quantities:\n",
    "$P(\\text{spam} | \\text{email})$ and $P(\\text{ham} | \\text{email})$ and compare them. It is useful to break the task down into smaller tasks as follows:\n",
    "\n",
    "1 - Write function **count_words_in_emails** which takes training emails and training labels and returns a dictionary containing the number of spam (and ham) emails that the word appeared in. Keep in mind to account for the Zero Probability mentioned earlier.\n",
    "\n",
    "2 - Build a dictionary containing the spam and ham fractions in the training data.\n",
    "\n",
    "3 - Use the above functions and write a function **P_w_given_c** to compute $P(\\text{word} | \\text{class})$\n",
    "\n",
    "4 - Compute $P(\\text{email} | \\text{class})= P(\\text{word_1} | \\text{class}) P(\\text{word_2} | \\text{class}).. P(\\text{word_n} | \\text{class})$ for the two classes \"spam\" and \"ham\" for all the emails in the test set.\n",
    "Note: Skip the words that do not exist in the training data.\n",
    "\n",
    "5 - Compare $P(\\text{email} | \\text{spam})$ and $P(\\text{email} | \\text{ham}) to get the classification of the \"email\" for all the emails in the test set.\n",
    "\n",
    "6 - Compute the accuracy of your model using the test set.\n",
    "Note: Using the same random seed used to split the data (42) you should get a classification accuracy of $84.82$%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d109b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0cae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df = pd.read_csv('emails.csv')\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc316b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffles the dataset\n",
    "temp_emails_df = emails_df.sample(frac = 1, ignore_index = True, random_state = 42)\n",
    "# Removes the word \"Subject:\" which comprises the first 9 characters of each email. Also, convert it to a numpy array.\n",
    "X = temp_emails_df.text.apply(lambda x: x[9:]).to_numpy()\n",
    "# Convert the labels to numpy array\n",
    "Y = temp_emails_df.spam.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77925337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X):\n",
    "    # Removing stop words and special characters\n",
    "\n",
    "    words_to_remove = set(stopwords.words('english') + list(string.punctuation))\n",
    "\n",
    "    if isinstance(X, str):\n",
    "        X = np.array([X])\n",
    "\n",
    "    X_cleaned = []\n",
    "    for i, email in enumerate(X):\n",
    "        email = np.array([i.lower() for i in word_tokenize(email) if i.lower() not in words_to_remove]).astype(X.dtype)\n",
    "        X_cleaned.append(email)\n",
    "        \n",
    "    if len(X) == 1:\n",
    "        return X_cleaned[0]\n",
    "    return X_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c804015",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = preprocessing(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_index = 0\n",
    "print(f\"Email before preprocessing:\\n {X[email_index]}\")\n",
    "print(\"============================================================================================\")\n",
    "print(f\"Email after preprocessing:\\n {X_cleaned[email_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f604f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 80% training and 20% testing\n",
    "\n",
    "TRAIN_SIZE = int(0.80*len(X_cleaned))\n",
    "\n",
    "X_train = X_cleaned[:TRAIN_SIZE]\n",
    "Y_train = Y[:TRAIN_SIZE]\n",
    "X_test = X_cleaned[TRAIN_SIZE:]\n",
    "Y_test = Y[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde28f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Fraction of spam emails in training set: {(Y_train.mean()*100):.2f}%, and in test set: {(Y_test.mean()*100):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b46d8d",
   "metadata": {},
   "source": [
    "# Your code starts here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72655a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c79af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0161676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a3878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
