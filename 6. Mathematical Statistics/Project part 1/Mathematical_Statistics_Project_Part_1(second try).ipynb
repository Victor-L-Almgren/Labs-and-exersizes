{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e164b769",
   "metadata": {},
   "source": [
    "# Mathematical Statistics Project - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa2adf",
   "metadata": {},
   "source": [
    "### Naive Bayes Algorithm: Spam/Ham Classification\n",
    "\n",
    "Naive Bayes is a simple yet powerful probabilistic classifier based on Bayes' Theorem, with the assumption that the features (words in our case) are independent. In the context of email classification, it is used to classify emails as either \"spam\" or \"ham\" (non-spam). Below is a step-by-step explanation of how Naive Bayes works for this task:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Understanding Bayes' Theorem**\n",
    "\n",
    "The algorithm uses **Bayes’ Theorem** to compute the probability of an email being spam given the words it contains. Bayes’ Theorem is expressed as:\n",
    "\n",
    "\n",
    "$$P(\\text{spam} | \\text{email}) = \\frac{P(\\text{email} | \\text{spam}) \\cdot P(\\text{spam})}{P(\\text{email})}$$\n",
    "\n",
    "\n",
    "Where:\n",
    "- $P(\\text{spam} | \\text{email})$ is the posterior probability of the email being spam, given that the words in the email are known.\n",
    "- $P(\\text{email} | \\text{spam})$ is the likelihood of seeing those words in a spam email.\n",
    "- $P(\\text{spam})$ is the prior probability of any random email being spam.\n",
    "- $P(\\text{email})$ is the probability of those words appearing in any email (this acts as a normalization factor).\n",
    "\n",
    "Since $P(\\text{email})$ is constant for both spam and ham classification, it can be ignored for comparison purposes.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Defining the Problem (Feature Set)**\n",
    "\n",
    "In this example, the features are the words in the email. For simplicity, let's assume we have a vocabulary with three words: `money`, `win`, and `lottery`.\n",
    "\n",
    "The email to classify is: **“win money lottery”**\n",
    "\n",
    "We want to calculate:\n",
    "\n",
    "$P(\\text{spam} | \\text{win money lottery}) \\quad \\text{vs} \\quad P(\\text{ham} | \\text{win money lottery})$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Collecting Probabilities from Training Data**\n",
    "\n",
    "We need the following probabilities from the training data:\n",
    "\n",
    "1. **Prior Probabilities**:\n",
    "   - $P(\\text{spam})$: Probability that any random email is spam.\n",
    "   - $P(\\text{ham})$: Probability that any random email is ham.\n",
    "\n",
    "2. **Likelihood Probabilities**:\n",
    "   - $P(\\text{win} | \\text{spam})$: Probability that \"win\" appears in a spam email.\n",
    "   - $P(\\text{money} | \\text{spam})$: Probability that \"money\" appears in a spam email.\n",
    "   - $P(\\text{lottery} | \\text{spam})$: Probability that \"lottery\" appears in a spam email.\n",
    "   - Similar probabilities for the words in ham emails.\n",
    "\n",
    "### Example:\n",
    "Suppose we have training data that results in the following counts:\n",
    "\n",
    "- Out of 1000 emails:\n",
    "  - 400 are spam emails, and 600 are ham emails.\n",
    "  \n",
    "  From spam emails:\n",
    "  - \"win\" appears in 300 out of 400 spam emails.\n",
    "  - \"money\" appears in 350 out of 400 spam emails.\n",
    "  - \"lottery\" appears in 200 out of 400 spam emails.\n",
    "\n",
    "  From ham emails:\n",
    "  - \"win\" appears in 100 out of 600 ham emails.\n",
    "  - \"money\" appears in 150 out of 600 ham emails.\n",
    "  - \"lottery\" appears in 50 out of 600 ham emails.\n",
    "\n",
    "#### **Calculating Prior Probabilities**:\n",
    "- $P(\\text{spam}) = \\frac{400}{1000} = 0.4$\n",
    "- $P(\\text{ham}) = \\frac{600}{1000} = 0.6$\n",
    "\n",
    "#### **Calculating Likelihood Probabilities**:\n",
    "For spam:\n",
    "- $P(\\text{win} | \\text{spam}) = \\frac{300}{400} = 0.75$\n",
    "- $P(\\text{money} | \\text{spam}) = \\frac{350}{400} = 0.875$\n",
    "- $P(\\text{lottery} | \\text{spam}) = \\frac{200}{400} = 0.5$\n",
    "\n",
    "For ham:\n",
    "- $P(\\text{win} | \\text{ham}) = \\frac{100}{600} = 0.167$\n",
    "- $P(\\text{money} | \\text{ham}) = \\frac{150}{600} = 0.25$\n",
    "- $P(\\text{lottery} | \\text{ham}) = \\frac{50}{600} = 0.083$\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Applying Naive Bayes Formula**\n",
    "\n",
    "We now calculate the **posterior probabilities** for both spam and ham:\n",
    "\n",
    "#### For Spam:\n",
    "\n",
    "$P(\\text{spam} | \\text{win money lottery}) \\propto P(\\text{spam}) \\cdot P(\\text{win} | \\text{spam}) \\cdot P(\\text{money} | \\text{spam}) \\cdot P(\\text{lottery} | \\text{spam})$\n",
    "Substitute the values:\n",
    "\n",
    "$P(\\text{spam} | \\text{win money lottery}) \\propto 0.4 \\cdot 0.75 \\cdot 0.875 \\cdot 0.5 = 0.13125$\n",
    "\n",
    "#### For Ham:\n",
    "\n",
    "$P(\\text{ham} | \\text{win money lottery}) \\propto P(\\text{ham}) \\cdot P(\\text{win} | \\text{ham}) \\cdot P(\\text{money} | \\text{ham}) \\cdot P(\\text{lottery} | \\text{ham})$\n",
    "Substitute the values:\n",
    "\n",
    "$P(\\text{ham} | \\text{win money lottery}) \\propto 0.6 \\cdot 0.167 \\cdot 0.25 \\cdot 0.083 = 0.00208$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Normalization & Decision**\n",
    "\n",
    "Although we can normalize the values to get actual probabilities, we can directly compare the two quantities:\n",
    "\n",
    "- $P(\\text{spam} | \\text{win money lottery}) = 0.13125$\n",
    "- $P(\\text{ham} | \\text{win money lottery}) = 0.00208$\n",
    "\n",
    "Since $P(\\text{spam} | \\text{win money lottery})$ is much larger than $P(\\text{ham} | \\text{win money lottery})$, we classify the email as **Spam**.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Handling Zero Probabilities (Smoothing)**\n",
    "\n",
    "In practice, some words may not appear in the training set for spam or ham, leading to zero probabilities (e.g., $P(\\text{win} | \\text{spam}) = 0$). To avoid this we assume that each word appeard at least in one Spam email and one ham email, i.e., we start counting each word from 1.\n",
    "\n",
    "---\n",
    "\n",
    "### **Tasks**\n",
    "\n",
    "The task is to implement the Naive Bayes algorithm from scratch. You will use the attached **emails.csv** file for this task.\n",
    "\n",
    "The first step is to preprocess the emails text and transform it into an easier format. An important step in preprocessing the text is to remove what is called **stopwords**. These are words that exist in the text but does not convey much information like prepositions and pronouns. The same holds for punctuations which needs to be removed as well. The second step is called **tokenization** where the email words are split and stored as an array of tokens (words).\n",
    "\n",
    "To help you through this part, the code snippet provided for you below provides useful instructions to load the data as a Pandas DataFrame and uses the **NLTK** library to remove stopwords. Use the **preprocessing** function provided to get a cleaned and tokenized version of the emails. The last code snippet provided for you is for splitting the data into training and testing sets.\n",
    "\n",
    "To implement the Naive Bayes algorithm you need to write functions to estimate the following quantities:\n",
    "$P(\\text{spam} | \\text{email})$ and $P(\\text{ham} | \\text{email})$ and compare them. It is useful to break the task down into smaller tasks as follows:\n",
    "\n",
    "1 - Write function **count_words_in_emails** which takes training emails and training labels and returns a dictionary containing the number of spam (and ham) emails that the word appeared in. Keep in mind to account for the Zero Probability mentioned earlier.\n",
    "\n",
    "2 - Build a dictionary containing the spam and ham fractions in the training data.\n",
    "\n",
    "3 - Use the above functions and write a function **P_w_given_c** to compute $P(\\text{word} | \\text{class})$\n",
    "\n",
    "4 - Compute $P(\\text{email} \\mid \\text{class}) = P(\\text{word}_1 \\mid \\text{class}) \\times P(\\text{word}_2 \\mid \\text{class}) \\times \\dots \\times P(\\text{word}_n \\mid \\text{class})$ for the two classes \"spam\" and \"ham\" for all the emails in the test set.\n",
    "Note: Skip the words that do not exist in the training data.\n",
    "\n",
    "5 - Compare $P(\\text{email} | \\text{spam})$ and $P(\\text{email} | \\text{ham})$ to get the classification of the \"email\" for all the emails in the test set.\n",
    "\n",
    "6 - Compute the accuracy of your model using the test set.\n",
    "Note: Using the same random seed used to split the data (42) you should get a classification accuracy of $84.82$%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "594bbbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d109b239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\victo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\victo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d0cae4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df = pd.read_csv('emails.csv')\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc316b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffles the dataset\n",
    "temp_emails_df = emails_df.sample(frac = 1, ignore_index = True, random_state = 42)\n",
    "# Removes the word \"Subject:\" which comprises the first 9 characters of each email. Also, convert it to a numpy array.\n",
    "X = temp_emails_df.text.apply(lambda x: x[9:]).to_numpy()\n",
    "# Convert the labels to numpy array\n",
    "Y = temp_emails_df.spam.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77925337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X):\n",
    "    # Removing stop words and special characters\n",
    "\n",
    "    words_to_remove = set(stopwords.words('english') + list(string.punctuation))\n",
    "\n",
    "    if isinstance(X, str):\n",
    "        X = np.array([X])\n",
    "\n",
    "    X_cleaned = []\n",
    "    for i, email in enumerate(X):\n",
    "        email = np.array([i.lower() for i in word_tokenize(email) if i.lower() not in words_to_remove]).astype(X.dtype)\n",
    "        X_cleaned.append(email)\n",
    "        \n",
    "    if len(X) == 1:\n",
    "        return X_cleaned[0]\n",
    "    return X_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c804015",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = preprocessing(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac5e256a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email before preprocessing:\n",
      " re : energy derivatives conference - may 29 , toronto  good morning amy :  vince kaminski will need the following :  an lcd projector to hook up to a lap tap for his presentation  he will have dinner with the conference organizers and speakers on the 29 th .  he will need 2 nights ( the 28 th and the 29 th ) hotel reservations .  he will send you an abstract shortly .  thanks and have a great day !  shirley crenshaw  713 - 853 - 5290  amy aldous on 03 / 31 / 2000 10 : 50 : 11 am  to : shirley . crenshaw @ enron . com  cc :  subject : re : energy derivatives conference - may 29 , toronto  ms . crenshaw ,  thank you for sending the bio so quickly . it ' s exactly what i was looking  for .  we are planning to compile the conference speakers ' papers for distribution  to the participants . while i will not need dr . kaminski ' s contribution for  several weeks , an abstract of his presentation as soon as possible would be  very useful to the conference organizers .  i will also need the following information :  - dr . kaminski ' s audio / video equipment requirements for his presentation  - will he be joining the conference organizers and speakers for dinner on  may 29 ?  - which nights will he be staying in toronto ? i will reserve a room at the  conference hotel  - any dietary restrictions or special requests  your help is much appreciated .  best wishes ,  amy  at 11 : 50 am 3 / 30 / 00 - 0600 , you wrote :  >  > amy :  >  > attached please find a short \" bio \" for dr . kaminski . please let me know  > if i can help further .  >  >  > ( see attached file : vincent kaminski bio . doc )  * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *  amy aldous , conference co - ordinator  centre for advanced studies in finance  university of waterloo  waterloo , on n 2 l 3 gl  tel : ( 519 ) 888 - 4567 ext . 5728  fax : ( 519 ) 888 - 7562  email : aaldous @ uwaterloo . ca  * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "============================================================================================\n",
      "Email after preprocessing:\n",
      " ['energy' 'derivatives' 'conference' 'may' '29' 'toronto' 'good' 'morning'\n",
      " 'amy' 'vince' 'kaminski' 'need' 'following' 'lcd' 'projector' 'hook'\n",
      " 'lap' 'tap' 'presentation' 'dinner' 'conference' 'organizers' 'speakers'\n",
      " '29' 'th' 'need' '2' 'nights' '28' 'th' '29' 'th' 'hotel' 'reservations'\n",
      " 'send' 'abstract' 'shortly' 'thanks' 'great' 'day' 'shirley' 'crenshaw'\n",
      " '713' '853' '5290' 'amy' 'aldous' '03' '31' '2000' '10' '50' '11'\n",
      " 'shirley' 'crenshaw' 'enron' 'com' 'cc' 'subject' 'energy' 'derivatives'\n",
      " 'conference' 'may' '29' 'toronto' 'ms' 'crenshaw' 'thank' 'sending' 'bio'\n",
      " 'quickly' 'exactly' 'looking' 'planning' 'compile' 'conference'\n",
      " 'speakers' 'papers' 'distribution' 'participants' 'need' 'dr' 'kaminski'\n",
      " 'contribution' 'several' 'weeks' 'abstract' 'presentation' 'soon'\n",
      " 'possible' 'would' 'useful' 'conference' 'organizers' 'also' 'need'\n",
      " 'following' 'information' 'dr' 'kaminski' 'audio' 'video' 'equipment'\n",
      " 'requirements' 'presentation' 'joining' 'conference' 'organizers'\n",
      " 'speakers' 'dinner' 'may' '29' 'nights' 'staying' 'toronto' 'reserve'\n",
      " 'room' 'conference' 'hotel' 'dietary' 'restrictions' 'special' 'requests'\n",
      " 'help' 'much' 'appreciated' 'best' 'wishes' 'amy' '11' '50' '3' '30' '00'\n",
      " '0600' 'wrote' 'amy' 'attached' 'please' 'find' 'short' '``' 'bio' '``'\n",
      " 'dr' 'kaminski' 'please' 'let' 'know' 'help' 'see' 'attached' 'file'\n",
      " 'vincent' 'kaminski' 'bio' 'doc' 'amy' 'aldous' 'conference' 'co'\n",
      " 'ordinator' 'centre' 'advanced' 'studies' 'finance' 'university'\n",
      " 'waterloo' 'waterloo' 'n' '2' 'l' '3' 'gl' 'tel' '519' '888' '4567' 'ext'\n",
      " '5728' 'fax' '519' '888' '7562' 'email' 'aaldous' 'uwaterloo' 'ca']\n"
     ]
    }
   ],
   "source": [
    "email_index = 0\n",
    "print(f\"Email before preprocessing:\\n {X[email_index]}\")\n",
    "print(\"============================================================================================\")\n",
    "print(f\"Email after preprocessing:\\n {X_cleaned[email_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f604f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 80% training and 20% testing\n",
    "\n",
    "TRAIN_SIZE = int(0.80*len(X_cleaned))\n",
    "\n",
    "X_train = X_cleaned[:TRAIN_SIZE]\n",
    "Y_train = Y[:TRAIN_SIZE]\n",
    "X_test = X_cleaned[TRAIN_SIZE:]\n",
    "Y_test = Y[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cde28f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of spam emails in training set: 24.31%, and in test set: 22.16%\n"
     ]
    }
   ],
   "source": [
    "print(f'Fraction of spam emails in training set: {(Y_train.mean()*100):.2f}%, and in test set: {(Y_test.mean()*100):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d8b26cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712002\n"
     ]
    }
   ],
   "source": [
    "result = 0\n",
    "for email in X_train:\n",
    "    for word in email:\n",
    "        result +=1\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b46d8d",
   "metadata": {},
   "source": [
    "# Your code starts here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c72655a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spam_Ham_Classifier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train, Y_train):  \n",
    "        spam_emails = []\n",
    "        ham_emails = []\n",
    "\n",
    "        for i, email in enumerate(X_train):\n",
    "            if Y_train[i] == 1:\n",
    "                spam_emails.append(set(email))\n",
    "            else:\n",
    "                ham_emails.append(set(email))\n",
    "\n",
    "        self.all_words_set = set(np.concatenate(X_train))\n",
    "        self.spam_ham_counts = {}\n",
    "\n",
    "        for word in self.all_words_set:\n",
    "            self.spam_ham_counts[word] = {0:1, 1:1}\n",
    "\n",
    "        for word in self.all_words_set:\n",
    "            for email in spam_emails:\n",
    "                if word in email:\n",
    "                    self.spam_ham_counts[word][1]+=1\n",
    "\n",
    "        for word in self.all_words_set:\n",
    "            for email in ham_emails:\n",
    "                if word in email:\n",
    "                    self.spam_ham_counts[word][0]+=1\n",
    "\n",
    "    def predict(self, email):\n",
    "        spam_prob = 1\n",
    "        ham_prob = 1\n",
    "\n",
    "        for word in email: \n",
    "            if word in self.spam_ham_counts.keys():\n",
    "                spam_prob *= self.spam_ham_counts[word][1]\n",
    "                ham_prob *= self.spam_ham_counts[word][0]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if ham_prob > spam_prob:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbd15c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8525305410122164\n"
     ]
    }
   ],
   "source": [
    "# Creating object and fitting the data\n",
    "identifyer = Spam_Ham_Classifier()\n",
    "identifyer.fit(X_train, Y_train)\n",
    "\n",
    "# Making prdictions\n",
    "predictions = []\n",
    "for email in X_test:\n",
    "    pred = identifyer.predict(email)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# Validating the model\n",
    "results = []\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] == Y_test[i]:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "print(f'accuracy: {sum(results) / len(results)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
