{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Code: DS4003 \n",
    "# Course Name: Principles and Techniques for Data Science \n",
    "# Lab Session: 01 - Data Cleaning\n",
    "\n",
    "### Some contents of this lab are adapted from UC Berkeley's Data100 course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first lab is meant to introduce you to techniques related to data manipulation and data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.options.display.max_rows = 7\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.precision', 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "Read Hadley Wickham's _R for Data Science_ book: https://r4ds.had.co.nz/tidy-data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try our first untidy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut1 = pd.read_csv('untidy1.csv')\n",
    "ut1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to read in 'untidy1.csv'  the data with a different delimiter \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ut1 = pd.read_csv('untidy1.csv', sep='\\s+')\n",
    "ut1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try another untidy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut2 = pd.read_csv('untidy2.csv')\n",
    "ut2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut2 = pd.read_csv('untidy2.csv', sep=\"\\s+\")\n",
    "ut2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the output above we can see that 1999 and 2000 appear as column names. This doesnt look right. Let's use the melt function on these two columns to make it more tidy\n",
    "\n",
    "Read here about the melt function: https://pandas.pydata.org/docs/reference/api/pandas.melt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut = ut2.melt(id_vars=['country'], value_vars=['1999', '2000'])\n",
    "ut.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We still need to rename the column, we can do it while melting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut = ut2.melt(id_vars=['country'], value_vars=['1999', '2000'], var_name='year')\n",
    "ut.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at a big untidy dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = pd.read_csv('tb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us take a look at the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The columns names are difficult to understand, let's see the metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_meta = pd.read_csv('tb_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the variables specific to to the columns presnt in tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_meta = tb_meta[tb_meta['variable_name'].isin(tb.columns)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### the dataset and code_list colunms are not that useful, so we remove them\n",
    "curr_meta = curr_meta.drop(columns=['dataset', 'code_list'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(curr_meta.shape[0]): \n",
    "    entry = curr_meta.iloc[i]\n",
    "    print(f'{entry.variable_name}: {entry.definition}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will define some functions to tidy up the tb dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function to drop 'iso2' and 'iso3'\n",
    "def drop_iso(df):\n",
    "    #YOUR CODDE HERE\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function to make a dataframe tidy using pd.melt\n",
    "## use country and year as id_vars\n",
    "## set var_name as 'entry'\n",
    "## set value_name as 'count'\n",
    "def make_tidy(df):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now introduce some new columns into our dataframe.\n",
    "We will use the df.assign function. You can read more about it https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function to introduce two columns 'sex' and 'agecodes'\n",
    "## The values of sex and agecodes should be extracted from the 'codes' value defined in the function\n",
    "## drop the entry column after you are done\n",
    "\n",
    "def split_entry(df):\n",
    "    codes = df['entry'].str.split('_').str[-1]\n",
    "    #YOUR CODE HERE\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will define a function to format the age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_from_code(df):\n",
    "    return df.assign(age=df['agecode'].replace({\n",
    "        '014': '0-14',\n",
    "        '04': '0-4',\n",
    "        '1524': '15-24',\n",
    "        '2534': '25-34',\n",
    "        '3544': '35-44',\n",
    "        '4554': '45-54',\n",
    "        '5564': '55-64',\n",
    "        '65': '65+',\n",
    "    })).drop(columns='agecode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the code below to see effects of the methods you implemented\n",
    "\n",
    "We will use the DataFrame.pipe function. You can read more about it here https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pipe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = (tb.pipe(drop_iso)\n",
    " .pipe(make_tidy)\n",
    " .pipe(split_entry)\n",
    " .pipe(age_from_code)\n",
    ")\n",
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now there are a lots of NaN value in the dataframe, lets drop them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's select a subset of the data. Select a subset of the data that shows the average number of cases for countries that start with the letter H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidy data is especially useful for seaborn, the plotting library we will use extensively in this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a barplot with the subset created. The x-axis should be the count and teh y-axis should be the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of structured data isn't in CSV format, but in HTML, XML, JSON, YAML, etc. JSON might have a structure that Pandas can't read directly.\n",
    "\n",
    "Here's an example: a group of people collected information about US congressional legislators in YAML format.\n",
    "\n",
    "https://github.com/unitedstates/congress-legislators\n",
    "\n",
    "Here's one of the data files:\n",
    "\n",
    "https://github.com/unitedstates/congress-legislators/blob/master/legislators-current.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "legislators_path = 'legislators-current.yaml'\n",
    "legislators = yaml.safe_load(open(legislators_path))\n",
    "len(legislators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see below, the data is mostly stored in several dictionaries. \n",
    "Hence, to access the data, we need to access the dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislators[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data pertaining to the first legislator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = legislators[0]\n",
    "x['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the name of the first legislator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the bio of the first legislator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to generate a datetime object from the birthday string associated with a legislator's birthday. Use datetime.strptime(). Test your function on the first legilator, x. You can read more about it here https://www.programiz.com/python-programming/datetime/strptime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe called 'leg_df'  that has four columns 'id', 'first', 'last', and 'birthday' for all legislators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the current age of the legistlators in a new column 'age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a histogram of the newly created age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "Thd column religion from the original legistlators dataset has a few missing values. Create a new column in leg_df with the name 'religion' and extract the religion of each legislator for this colum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many null values do we have in the religion column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the null values in religion with 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Dataframes\n",
    "Now we will look at how to merge dataframes. Lets read in some new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_path = 'committees-current.yaml'\n",
    "comm_membership_path = 'committee-membership-current.yaml'\n",
    "\n",
    "comms = yaml.safe_load(open(comm_path))\n",
    "comm_membership = yaml.safe_load(open(comm_membership_path))\n",
    "print(len(comms), len(comm_membership))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comms[0]\n",
    "# thomas_id is a unique reference to the committee "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets create a dataframe from the commitees dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_df = pd.DataFrame(\n",
    "    columns=['name', 'thomas_id', 'type'],\n",
    "    data=[[c['name'], c['thomas_id'], c['type']] for c in comms]\n",
    ")\n",
    "comm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's take a look at the commitee memberships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_membership.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_membership['HSAG'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's create a dataframe from the commitee memberships dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "member_df = pd.DataFrame(\n",
    "    columns=['comm_id', 'leg_id'],\n",
    "    data=[[c, m['bioguide']] for c, members in comm_membership.items() for m in members]\n",
    ")\n",
    "member_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the member-df with comm_df on 'comm_id' and 'thomas_id'. Name it member_comm\n",
    "\n",
    "Read more about pd.merge here: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of legistlators belonging to each committee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge member_comm with with leg_df on 'leg_id',  and 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the average age of legislators in each committee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "* Drop the data with missing values (we did that for previous examples)\n",
    "* Estimate the missing value\n",
    "    1. use mean, median or mode \n",
    "    2. Use inference engine to estimate \n",
    "    3. Some values should not be estimated (e.g., religion in previous example)\n",
    "* Zero fill or value fill "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampling \n",
    "\n",
    "if we use pandas, we can simply use sample function. Read more here: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 20% of data from the tidy dataframe\n",
    "A = tidy.sample(frac=0.2)\n",
    "print(A.shape, tidy.shape)\n",
    "# sample 20 data \n",
    "B = tidy.sample(n=20)\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we need to randomly sample images or files. for example files in the current directory?\n",
    "We can use the Python funtion random. Read more about random here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random \n",
    "files = os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files is a list files in your current working directory. Sample 2 random files from your files directiory and print their names.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we have to sample data from numpy array \n",
    "We can use np.random. Read more about it here https://numpy.org/doc/stable/reference/random/index.html. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First use any two np.random functions to generate an array of random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly sample 3 elements without replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly sample 3 elements with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
